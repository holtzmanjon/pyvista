{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> TSPEC : multiple orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i> This is an older notebook that is in need of updating and development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvista import imred, tv, spectra\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyvista uses a display tool defined in the tv module. To use the interactive\n",
    "display in a notebook, set the display to be an external display window, e.g. with \n",
    "<code>\n",
    "%matplotlib qt\n",
    "</code>\n",
    "Instantiate a tv object, here we just call it t, but you could call it whatever you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "t=tv.TV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic tool for basic image reduction is a Reducer object, defined in the imred module. Instantiate a reducer here. The main argument is an instrument name, which tells it to read a YAML configuration file for the specified instrument. We also give it an optional dir= argument to specify the default directory from which to read images, if a directory is not specified in subsequent commands that read images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tspec=imred.Reducer(inst='TSPEC',dir='/home/holtz/red/UT191026/TSPEC',nfowler=8)\n",
    "a=tspec.reduce(21)\n",
    "dark=tspec.reduce(22)\n",
    "t.clear()\n",
    "t.tv(a)\n",
    "a=a.subtract(dark)\n",
    "t.tv(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A main method of the reducer object is the reduce() method. Without any additional arguments, reduce() will read an image from disk, subtract the overscan (region(s) as determined from the instrument configuration file), compute an uncertainty array using the gain and readout noise from the instrument configuration file, and return a CCDData object with the data, uncertainty, and mask. \n",
    "<p>\n",
    "To specify the input image, we could pass a string with the file name. If the string does not include a '/', it will read from the default input directory.\n",
    "<p>\n",
    "If the file can be identified with a unique integer, then you can just specify this number, which can be very convenient. This is turned into a character string using the formstr attribute define in the configuration file, which is used to search for the file to read.\n",
    "<p>\n",
    "We can display the image using the tv() method of our display tool, which can take as input a Data object, and numpy array, or a FITS HDU object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Calibration: make and apply flat field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add additional arguments to reduce(), we can add additional calibration steps. For example, to flat field the data, we would add a flat= keyword through which we give the reducer a flat field. To add a spatial bias subtraction, we would add a bias= keyword through which we give the reducer a superbias frame.\n",
    "<br>\n",
    "First, however, we have to make the calibration products, which is accomplished using the mkflat(), mkbias(), etc methods. These take as input a list of frames to be used to construct the master calibration frame (e.g.. superflat). For ARCES, we will keep the spectral shape of the flats for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create biases and flats. Note that for flats, we have to do scattered light removal, which can be done on reduction of individual images, but since it is slow, we will do it on the combined flat. If we add the display= keyword, giving a display object, then the calibration frames will be displayed, showing each input frame relative to the master frame, so you can inspect and make sure that bad frames are not being included in the combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and display a star spectral image. For ARCES, we do not apply a flat field here, since we only have flats with the orders, which can move around a bit. Instead, we will use \"1D\" flats later in the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crstar=red.crrej(star,crbox='lacosmic',display=t,objlim=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Tracing and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=[[135,235],[295,395],[435,535],[560,660],[735,830]]\n",
    "apers=[155,316,454,591,761]\n",
    "\n",
    "t.clear()\n",
    "t.tv(a)\n",
    "traces=spectra.Trace(degree=3,rows=rows,lags=range(-75,75),transpose=False)\n",
    "traces.trace(a,apers,sc0=350,plot=t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces.write('TSPEC_traces.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces=spectra.Trace(file='./TSPEC_traces.fits')\n",
    "vars(traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum up the arc lamp exposures, get the shift for the existing traces, and extract. Note that if you have a multiprocessor machine, you can specify number of threads to use for the extraction, which will speed things up (but the default threads=0 isn't too terrible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "acr=tspec.reduce(21) #,crbox=[11,1])\n",
    "t.clear()\n",
    "t.tv(acr)\n",
    "traces.pix0=30\n",
    "order=7\n",
    "out=traces.extract(acr,rad=20,plot=t)\n",
    "out.shape\n",
    "out.data=out.data - scipy.signal.medfilt(out.data,kernel_size=[1,201])\n",
    "\n",
    "#for aper,row in zip(apers,rows) :\n",
    "    #out=traces.extract(acr,rad=20,plot=t)\n",
    "    #out.data=out.data - scipy.signal.medfilt(out.data,kernel_size=[1,201])\n",
    "    #wcal=spectra.WaveCal(type='chebyshev',orders=[order],degree=3)\n",
    "    #w=np.atleast_2d(wav[order-3,0,:][::-1])*1.e4\n",
    "    #bd=np.where(~np.isfinite(w))\n",
    "    #w[bd[0],bd[1]]=9000.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do line identification based on previously identified lines, and wavelength fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav=fits.open('/home/holtz/red/tspec_wave.fits')[0].data\n",
    "\n",
    "for order in range(7,3,-1) : \n",
    "    wcal=spectra.WaveCal(type='chebyshev',degree=3,orders=[order])\n",
    "    wcal.model=wcal.getmod()\n",
    "\n",
    "    wcal.identify(out[7-order],wav=np.atleast_2d(wav[order-3,0,::-1]*1.e4),\n",
    "                  thresh=10,file='OHll.dat',plot=True,rad=3)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order=7\n",
    "wcal=spectra.WaveCal(type='chebyshev2D',degree=3,orders=[7,6,5,4,3])\n",
    "wcal.set_spectrum(out)\n",
    "wcal.model = wcal.getmod()\n",
    "vars(wcal)\n",
    "#wcal=spectra.WaveCal(type='chebyshev',degree=3,orders=[order])\n",
    "\n",
    "\n",
    "#wav=fits.open('/home/holtz/red/tspec_wave.fits')[0].data\n",
    "#fig,ax=plots.multi(1,2)\n",
    "#t.clear() \n",
    "#t.tv(wav[::-1,0,::-1])\n",
    "#t.tv(out)\n",
    "#wcal.identify(out[7-order],wav=np.atleast_2d(wav[order-3,0,::-1]*1.e4),\n",
    "#              thresh=10,file='OHll.dat',plot=fig,rad=3)   \n",
    "\n",
    "\n",
    "wcal.identify(out,wav=np.atleast_2d(wav[::-1,0,::-1]*1.e4),\n",
    "              thresh=50,file='OHll.dat',plot=True,rad=3)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcal.model\n",
    "\n",
    "\n",
    "#wcal.wave(image=out[7-order].shape)\n",
    "#wcal.identify(out[7-order],thresh=50,file='OHll.dat',plot=fig,rad=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now reduce an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get shift of traces, and extract. Alternatively, you could use a single call to retrace(), which will do the find() and then trace() using the shifted stored model as a starting guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the wavelengths for all pixels from the wavelength solution and plot extracted spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wav.add_wave(imec)\n",
    "plt.figure()\n",
    "for row in range(len(imec.wave)) :\n",
    "    plt.plot(imec.wave[row],imec.data[row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample onto logarithmic wavelength grid and combine orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnew=10**np.arange(3.5,4.0,5.5e-6)\n",
    "comb=wav.scomb(imec.divide(flat1d),wnew,average=True,usemask=True)\n",
    "plt.clf()\n",
    "plt.plot(wnew,comb.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
